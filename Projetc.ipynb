{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake News Detection System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake=pd.read_csv(\"C:/Users/Admin/OneDrive/Desktop/5th Semester/AIML/Fake News Detection System/Fake.csv\")\n",
    "data_true=pd.read_csv(\"C:/Users/Admin/OneDrive/Desktop/5th Semester/AIML/Fake News Detection System/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake[\"class\"]=0\n",
    "data_true[\"class\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.shape, data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake_manual_testing=data_fake.tail(10)\n",
    "for i in range(23480,23470,-1):\n",
    "    data_fake.drop([i] , axis=0 ,inplace=True)\n",
    "    \n",
    "    \n",
    "data_true_manula_testing=data_true.tail(10)\n",
    "for i in range(21416,21406,-1):\n",
    "    data_true.drop([i] , axis=0 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.shape , data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake_manual_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true_manula_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge=pd.concat([data_fake,data_true])\n",
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_merge.drop(['title','subject','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to process the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordop(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('/[.*?/]','',text)\n",
    "    text=re.sub('//W','',text)\n",
    "    text=re.sub('https?://\\S+|www/.\\S+','',text)\n",
    "    text=re.sub('<.*?>+','',text)\n",
    "    text=re.sub('[%s]'% re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('/n','',text)\n",
    "    text=re.sub('/w*/d/w','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(wordop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['text']\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test , x_train , y_test , y_train=train_test_split(x,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train=vectorization.fit_transform(x_train)\n",
    "xv_test=vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr=LR.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(xv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT=DecisionTreeClassifier()\n",
    "DT.fit(xv_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt=DT.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.score(xv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB=GradientBoostingClassifier(random_state=0)\n",
    "GB.fit(xv_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gb=GB.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB.score(xv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predict_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF=RandomForestClassifier(random_state=0)\n",
    "RF.fit(xv_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf=RF.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.score(xv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle\n",
    "\n",
    "# Saving the RF object to a file named \"A.pkl\"\n",
    "with open(\"A.pkl\", \"wb\") as file:\n",
    "    pickle.dump(LR, file)\n",
    "with open(\"B.pkl\", \"wb\") as file:\n",
    "    pickle.dump(DT, file)\n",
    "with open(\"C.pkl\", \"wb\") as file:\n",
    "    pickle.dump(GB, file)\n",
    "with open(\"D.pkl\", \"wb\") as file:\n",
    "    pickle.dump(RF, file)\n",
    "\n",
    "# Loading the RF object from the file \"A.pkl\"\n",
    "with open(\"A.pkl\", \"rb\") as file:\n",
    "    loaded_LR = pickle.load(file)\n",
    "with open(\"B.pkl\", \"rb\") as file:\n",
    "    loaded_DT = pickle.load(file)\n",
    "with open(\"C.pkl\", \"rb\") as file:\n",
    "    loaded_GB = pickle.load(file)\n",
    "with open(\"D.pkl\", \"rb\") as file:\n",
    "    loaded_RF = pickle.load(file)\n",
    "\n",
    "# Now you can use loaded_RF for making predictions or other tasks\n",
    "Predict1 = loaded_LR.predict(xv_test)\n",
    "Predict2 = loaded_DT.predict(xv_test)\n",
    "Predict3 = loaded_GB.predict(xv_test)\n",
    "Predict4 = loaded_RF.predict(xv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check the Authenticity of the News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Output_Label(n):\n",
    "    if n==0:\n",
    "        return \"Fake News!\"\n",
    "    elif n==1:\n",
    "        return \"This News is Authentic!\"\n",
    "def Manal_testing(news):\n",
    "    testing_news={\"text\":[news]}\n",
    "    new_def_test=pd.DataFrame(testing_news)\n",
    "    print(\"Worddrop\")\n",
    "    new_def_test[\"text\"]=new_def_test[\"text\"].apply(wordop)\n",
    "    new_x_test=new_def_test[\"text\"]\n",
    "    print(\"Vectorize\")\n",
    "    new_xv_test=vectorization.transform(new_x_test)\n",
    "    print(\"Model1\")\n",
    "    Predict1(new_xv_test)\n",
    "    print(\"Model2\")\n",
    "    Predict2(new_xv_test)\n",
    "    print(\"Model3\")\n",
    "    Predict3(new_xv_test)\n",
    "    print(\"Model4\")\n",
    "    Predict4(new_xv_test)\n",
    "    return print(\"/n/nLR Prediction:{}  /nDT Prediction:{} /nGBC Prediction:{}  /nRFC Prediction:{}\".format(Output_Label(Predict1[0]),Output_Label(Predict2[0]),Output_Label(Predict3[0]),Output_Label(Predict4[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = str(input())\n",
    "Manal_testing(news)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
